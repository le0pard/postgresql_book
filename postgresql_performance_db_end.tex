\section{Оптимизация БД и приложения}
Для быстрой работы каждого запроса в вашей базе в основном требуется следующее:
\begin{enumerate}
 \item Отсутствие в базе мусора, мешающего добраться до актуальных данных. Можно сформулировать две подзадачи:
 \begin{enumerate}
  \item Грамотное проектирование базы. Освещение этого вопроса выходит далеко за рамки этой статьи.
  \item Сборка мусора, возникающего при работе СУБД.
 \end{enumerate}
 \item Наличие быстрых путей доступа к данным~--- индексов.
 \item Возможность использования оптимизатором этих быстрых путей.
 \item Обход известных проблем.
\end{enumerate}

\subsection{Поддержание базы в порядке}
В данном разделе описаны действия, которые должны периодически выполняться для каждой базы. От разработчика требуется только настроить 
их автоматическое выполнение (при помощи cron) и опытным путём подобрать оптимальную частоту.

\subsubsection{Команда ANALYZE}
Служит для обновления информации о распределении данных в таблице. Эта информация используется оптимизатором для выбора наиболее 
быстрого плана выполнения запроса.

Обычно команда используется в связке с VACUUM ANALYZE. Если в базе есть таблицы, данные в которых не изменяются и не удаляются, а лишь 
добавляются, то для таких таблиц можно использовать отдельную команду ANALYZE. Также стоит использовать эту команду для отдельной 
таблицы после добавления в неё большого количества записей.

\subsubsection{Команда REINDEX}
Команда REINDEX используется для перестройки существующих индексов.
Использовать её имеет смысл в случае:
\begin{itemize}
\item порчи индекса;
\item постоянного увеличения его размера.
\end{itemize}

Второй случай требует пояснений. Индекс, как и таблица, содержит блоки со старыми версиями записей. PostgreSQL не всегда может 
заново использовать эти блоки, и поэтому файл с индексом постепенно увеличивается в размерах. Если данные в таблице часто меняются, 
то расти он может весьма быстро.

Если вы заметили подобное поведение какого-то индекса, то стоит настроить для него периодическое выполнение команды REINDEX. 
Учтите: команда REINDEX, как и VACUUM FULL, полностью блокирует таблицу, поэтому выполнять её надо тогда, когда загрузка 
сервера минимальна.

\subsection{Использование индексов}
Опыт показывает, что наиболее значительные проблемы с производительностью вызываются отсутствием нужных индексов. Поэтому столкнувшись 
с медленным запросом, в первую очередь проверьте, существуют ли индексы, которые он может использовать. Если нет~--- постройте их.
Излишек индексов, впрочем, тоже чреват проблемами:
\begin{itemize}
\item Команды, изменяющие данные в таблице, должны изменить также и индексы. Очевидно, чем больше индексов построено для таблицы, 
тем медленнее это будет происходить.
\item Оптимизатор перебирает возможные пути выполнения запросов. Если построено много ненужных индексов, то этот перебор будет 
идти дольше.
\end{itemize}
Единственное, что можно сказать с большой степенью определённости~--- поля, являющиеся внешими ключами, и поля, по которым 
объединяются таблицы, индексировать надо обязательно.

\subsubsection{Команда EXPLAIN [ANALYZE]}
Команда EXPLAIN [запрос] показывает, каким образом PostgreSQL собирается выполнять ваш запрос. Команда EXPLAIN ANALYZE 
[запрос] выполняет запрос\footnote{и поэтому EXPLAIN ANALYZE DELETE \dots~--- не слишком хорошая идея} и показывает как 
изначальный план, так и реальный процесс его выполнения.

Чтение вывода этих команд~--- искусство, которое приходит с опытом. Для начала обращайте внимание на следующее:
\begin{itemize}
\item Использование полного просмотра таблицы (seq scan).
\item Использование наиболее примитивного способа объединения таблиц (nested loop).
\item Для EXPLAIN ANALYZE: нет ли больших отличий в предполагаемом количестве записей и реально выбранном? 
Если оптимизатор использует устаревшую статистику, то он может выбирать не самый быстрый план выполнения запроса.
\end{itemize}

Следует отметить, что полный просмотр таблицы далеко не всегда медленнее просмотра по индексу. Если, например, в 
таблице--справочнике несколько сотен записей, умещающихся в одном-двух блоках на диске, то использование индекса приведёт 
лишь к тому, что придётся читать ещё и пару лишних блоков индекса. Если в запросе придётся выбрать 80\% записей из большой 
таблицы, то полный просмотр опять же получится быстрее.

При тестировании запросов с использованием EXPLAIN ANALYZE можно воспользоваться настройками, запрещающими оптимизатору использовать
определённые планы выполнения. Например,
\begin{verbatim}
SET enable_seqscan=false;
\end{verbatim}

запретит использование полного просмотра таблицы, и вы сможете выяснить, прав ли был оптимизатор, отказываясь от использования 
индекса. Ни в коем случае не следует прописывать подобные команды в postgresql.conf! Это может ускорить выполнение нескольких запросов, 
но сильно замедлит все остальные!

\subsubsection{Использование собранной статистики}
Результаты работы сборщика статистики доступны через специальные системные представления. Наиболее интересны для 
наших целей следующие:
\begin{itemize}
\item \textbf{pg\_stat\_user\_tables} содержит~--- для каждой пользовательской таблицы в текущей базе данных~--- общее количество 
полных просмотров и просмотров с использованием индексов, общие количества записей, которые были возвращены в результате обоих 
типов просмотра, а также общие количества вставленных, изменённых и удалённых записей.
\item \textbf{pg\_stat\_user\_indexes} содержит~--- для каждого пользовательского индекса в текущей базе данных~--- общее количество 
просмотров, использовавших этот индекс, количество прочитанных записей, количество успешно прочитанных записей в таблице (может быть 
меньше предыдущего значения, если в индексе есть записи, указывающие на устаревшие записи в таблице).
\item \textbf{pg\_statio\_user\_tables} содержит~--- для каждой пользовательской таблицы в текущей базе данных~--- общее количество 
блоков, прочитанных из таблицы, количество блоков, оказавшихся при этом в буфере (см. пункт 2.1.1), а также аналогичную статистику 
для всех индексов по таблице и, возможно, по связанной с ней таблицей TOAST.
\end{itemize}

Из этих представлений можно узнать, в частности:
\begin{itemize}
 \item Для каких таблиц стоит создать новые индексы (индикатором служит большое количество полных просмотров и большое количество 
прочитанных блоков).
 \item Какие индексы вообще не используются в запросах. Их имеет смысл удалить, если, конечно, речь не идёт об индексах, 
обеспечивающих выполнение ограничений PRIMARY KEY и UNIQUE.
 \item Достаточен ли объём буфера сервера.
\end{itemize}

Также возможен <<дедуктивный>> подход, при котором сначала создаётся большое количество индексов, а затем неиспользуемые индексы удаляются.

\subsubsection{Возможности индексов в PostgreSQL}
\textbf{Функциональные индексы} Вы можете построить индекс не только по полю/нескольким полям таблицы, но и по выражению, зависящему от полей.
Пусть, например, в вашей таблице foo есть поле foo\_name, и выборки часто делаются по условию 
<<первая буква foo\_name = 'буква', в любом регистре>>.
Вы можете создать индекс
\begin{verbatim}
CREATE INDEX foo_name_first_idx 
ON foo ((lower(substr(foo_name, 1, 1))));
\end{verbatim}
и запрос вида
\begin{verbatim}
SELECT * FROM foo 
WHERE lower(substr(foo_name, 1, 1)) = 'ы';
\end{verbatim}
будет его использовать.

\textbf{Частичные индексы (partial indexes)} Под частичным индексом понимается индекс с предикатом WHERE. Пусть, например, 
у вас есть в базе таблица scheta с параметром uplocheno типа boolean. Записей, где uplocheno = false меньше, чем записей 
с uplocheno = true, а запросы по ним выполняются значительно чаще. Вы можете создать индекс
\begin{verbatim}
CREATE INDEX scheta_neuplocheno ON scheta (id)
WHERE NOT uplocheno;
\end{verbatim}
который будет использоваться запросом вида
\begin{verbatim}
SELECT * FROM scheta WHERE NOT uplocheno AND ...;
\end{verbatim}
Достоинство подхода в том, что записи, не удовлетворяющие условию WHERE,
просто не попадут в индекс.

\subsection{Перенос логики на сторону сервера}
Этот пункт очевиден для опытных пользователей PostrgeSQL и предназначен для тех, кто использует или переносит на 
PostgreSQL приложения, написанные изначально для более примитивных СУБД.

Реализация части логики на стороне сервера через хранимые процедуры, триггеры, правила\footnote{RULE~--- реализованное в 
PostgreSQL расширение стандарта SQL, позволяющее, в частности, создавать обновляемые представления} часто позволяет ускорить 
работу приложения. Действительно, если несколько запросов объединены в процедуру, то не требуется
\begin{itemize}
\item пересылка промежуточных запросов на сервер;
\item получение промежуточных результатов на клиент и их обработка.
\end{itemize}

Кроме того, хранимые процедуры упрощают процесс разработки и поддержки: изменения надо вносить только на стороне сервера, 
а не менять запросы во всех приложениях.

\subsection{Оптимизация конкретных запросов}
В этом разделе описываются запросы, для которых по разным причинам нельзя заставить оптимизатор использовать индексы, и 
которые будут всегда вызывать полный просмотр таблицы. Таким образом, если вам требуется использовать эти запросы в 
требовательном к быстродействию приложении, то придётся их изменить.

\subsubsection{SELECT count(*) FROM <огромная таблица>}
Функция count() работает очень просто: сначала выбираются все записи, удовлетворяющие условию, а потом к полученному набору 
записей применяется агрегатная функция~--- считается количество выбраных строк. 
Информация о видимости записи для текущей транзакции (а конкурентным транзакциям может быть видимо разное
количество записей в таблице!) не хранится в индексе, поэтому, даже если использовать для выполнения 
запроса индекс первичного ключа таблицы, всё равно потребуется чтение записей собственно из файла таблицы.

\textbf{Проблема} Запрос вида
\begin{lstlisting}[language=SQL,label=lst:sql_performance1,caption=SQL]
SELECT count(*) FROM foo;
\end{lstlisting}
осуществляет полный просмотр таблицы foo, что весьма долго для таблиц с большим количеством записей.

\textbf{Решение} Простого решения проблемы, к сожалению, нет. Возможны следу-
ющие подходы:
\begin{enumerate}
\item Если точное число записей не важно, а важен порядок\footnote{<<на нашем форуме более 10000 зарегистрированных 
пользователей, оставивших более 50000 сообщений!>>}, то можно использовать информацию о количестве 
записей в таблице, собранную при выполнении команды ANALYZE:
\begin{lstlisting}[language=SQL,label=lst:sql_performance2,caption=SQL]
SELECT reltuples FROM pg_class WHERE relname = 'foo';
\end{lstlisting}
\item Если подобные выборки выполняются часто, а изменения в таблице достаточно редки, то можно завести вспомогательную 
таблицу, хранящую число записей в основной. На основную же таблицу повесить триггер, который будет уменьшать это число 
в случае удаления записи и увеличивать в случае вставки. Таким образом, для получения количества записей потребуется лишь 
выбрать одну запись из вспомогательной таблицы.
\item Вариант предыдущего подхода, но данные во вспомогательной таблице обновляются через определённые промежутки времени (cron).
\end{enumerate}

\subsubsection{Медленный DISTINCT}
Текущая реализация DISTINCT для больших таблиц очень медленна. Но возможно использовать GROUP BY взамен DISTINCT. 
GROUP BY может использовать агрегирующий хэш, что значительно быстрее, чем DISTINCT.

\begin{lstlisting}[language=SQL,label=lst:sql_performance3,caption=DISTINCT]
postgres=# select count(*) from (select distinct i from g) a;
 count 
-------
 19125
(1 row)

Time: 580,553 ms


postgres=# select count(*) from (select distinct i from g) a;
 count 
-------
 19125
(1 row)

Time: 36,281 ms
\end{lstlisting}

\begin{lstlisting}[language=SQL,label=lst:sql_performance4,caption=GROUP BY]
postgres=# select count(*) from (select i from g group by i) a;
 count 
-------
 19125
(1 row)

Time: 26,562 ms


postgres=# select count(*) from (select i from g group by i) a;
 count 
-------
 19125
(1 row)

Time: 25,270 ms

\end{lstlisting}

\subsection{Оптимизация запросов с помощью pgFouine}
pgFouine\footnote{http://pgfouine.projects.postgresql.org/}~--- это 
анализатор log-файлов для PostgreSQL, используемый для генерации детальных отчетов из 
log-файлов PostgreSQL. pgFouine поможет определить, какие запросы следует оптимизировать в первую очередь.
pgFouine написан на языке программирования PHP с использованием объектно-ориентированных технологий и легко 
расширяется для поддержки специализированных отчетов, является свободным программным обеспечением и 
распространяется на условиях GNU General Public License. Утилита спроектирована таким образом, чтобы обработка 
очень больших log-файлов не требовала много ресурсов.

Для работы с pgFouine сначала нужно сконфигурировать PostgreSQL для создания нужного формата log-файлов:
\begin{itemize}
\item Чтобы включить протоколирование в syslog
\begin{lstlisting}[label=lst:sql_performance5,caption=pgFouine]
log_destination = 'syslog'
redirect_stderr = off
silent_mode = on
\end{lstlisting}
\item Для записи запросов, длящихся дольше n миллисекунд:
\begin{lstlisting}[label=lst:sql_performance6,caption=pgFouine]
log_min_duration_statement = n
log_duration = off
log_statement = 'none'
\end{lstlisting}
\end{itemize}

Для записи каждого обработанного запроса установите log\_min\_duration\_statement на 0. 
Чтобы отключить запись запросов, установите этот параметр на -1.

pgFouine~--- простой в использовании инструмент командной строки. Следующая команда создаёт 
HTML-отчёт со стандартными параметрами:
\begin{lstlisting}[label=lst:sql_performance7,caption=pgFouine]
pgfouine.php -file your/log/file.log > your-report.html
\end{lstlisting}

С помощью этой строки можно отобразить текстовый отчёт с 10 запросами на каждый экран на стандартном выводе:
\begin{lstlisting}[label=lst:sql_performance8,caption=pgFouine]
pgfouine.php -file your/log/file.log -top 10 -format text
\end{lstlisting}

Более подробно о возможностях, а также много полезных примеров, можно найти на официальном сайта проекта~--- 
http://pgfouine.projects.postgresql.org.


\section{Заключение}
К счастью, PostgreSQL не требует особо сложной настройки. В большинстве случаев вполне достаточно будет увеличить 
объём выделенной памяти, настроить периодическое поддержание базы в порядке и проверить наличие необходимых индексов. 
Более сложные вопросы можно обсудить в специализированном списке рассылки.
