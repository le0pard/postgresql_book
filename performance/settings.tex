\section{Настройка сервера}

В этом разделе описаны рекомендуемые значения параметров, влияющих на производительность СУБД. Эти параметры обычно устанавливаются в конфигурационном файле postgresql.conf и влияют на все базы в текущей установке.

\subsection{Используемая память}

\subsubsection{Общий буфер сервера: shared\_buffers}

PostgreSQL не читает данные напрямую с диска и не пишет их сразу на диск. Данные загружаются в общий буфер сервера, находящийся в разделяемой памяти, серверные процессы читают и пишут блоки в этом буфере, а затем уже изменения сбрасываются на диск.

Если процессу нужен доступ к таблице, то он сначала ищет нужные блоки в общем буфере. Если блоки присутствуют, то он может продолжать работу, если нет~--- делается системный вызов для их загрузки. Загружаться блоки могут как из файлового кэша ОС, так и с диска, и эта операция может оказаться весьма <<дорогой>>.

Если объём буфера недостаточен для хранения часто используемых рабочих данных, то они будут постоянно писаться и читаться из кэша ОС или с диска, что крайне отрицательно скажется на производительности.

В то же время не следует устанавливать это значение слишком большим: это НЕ вся память, которая нужна для работы PostgreSQL, это только размер разделяемой между процессами PostgreSQL памяти, которая нужна для выполнения активных операций. Она должна занимать меньшую часть оперативной памяти вашего компьютера, так как PostgreSQL полагается на то, что операционная система кэширует файлы, и не старается дублировать эту работу. Кроме того, чем больше памяти будет отдано под буфер, тем меньше останется операционной системе и другим приложениям, что может привести к своппингу.

К сожалению, чтобы знать точное число \lstinline!shared_buffers!, нужно учесть количество оперативной памяти системы, размер базы данных, число соединений и сложность запросов, так что лучше воспользуемся несколькими простыми правилами настройки.

На выделенных серверах полезным объемом для \lstinline!shared_buffers! будет значение 1/4 памяти в системе. Если у вас большие активные порции базы данных, сложные запросы, большое число одновременных соединений, длительные транзакции, вам доступен большой объем оперативной памяти или большее количество процессоров, то можно подымать это значение и мониторить результат, чтобы не привести к <<деградации>> (падению) производительности. Выделив слишком много памяти для базы данных, мы можем получить ухудшение производительности, поскольку PostgreSQL также использует кэш операционной системы (увеличение данного параметра более 40\% оперативной памяти может давать <<нулевой>> прирост производительности).

Для тонкой настройки параметра установите для него большое значение и потестируйте базу при обычной нагрузке. Проверяйте использование разделяемой памяти при помощи \lstinline!ipcs! или других утилит(например, \lstinline!free! или \lstinline!vmstat!). Рекомендуемое значение параметра будет примерно в 1,2~--2 раза больше, чем максимум использованной памяти. Обратите внимание, что память под буфер выделяется при запуске сервера, и её объём при работе не изменяется.

Также следует помнить, что на 32 битной системе (Linux) каждый процесс лимитирован в 4 ГБ адресного пространства, где хотя бы 1 ГБ зарезервирован ядром. Это означает, что не зависимо, сколько на машине памяти, каждый PostgreSQL инстанс сможет обратиться максимум к 3 ГБ памяти. А значит максимум для \lstinline!shared_buffers! в такой системе~--- 2--2.5 ГБ.

Хочу обратить внимание, что на Windows, большие значения для \lstinline!shared_buffers! не столь эффективны, как на Linux системах, и в результате лучшие результаты можно будет получить, если держать это значение относительно небольшое (от 64 МБ до 512 МБ) и использовать кэш системы вместо него.


\subsubsection{Память для сортировки результата запроса: work\_mem}


\lstinline!work_mem! параметр определяет максимальное количество оперативной памяти, которое может выделить одна операция сортировки, агрегации и др. Это не разделяемая память, \lstinline!work_mem! выделяется отдельно на каждую операцию (от одного до нескольких раз за один запрос). Разумное значение параметра определяется следующим образом: количество доступной оперативной памяти (после того, как из общего объема вычли память, требуемую для других приложений, и \lstinline!shared_buffers!) делится на максимальное число одновременных запросов умноженное на среднее число операций в запросе, которые требуют памяти.

Если объём памяти недостаточен для сортировки некоторого результата, то серверный процесс будет использовать временные файлы. Если же объём памяти слишком велик, то это может привести к своппингу.

Объём памяти задаётся параметром \lstinline!work_mem! в файле postgresql.conf. Единица измерения параметра~--- 1 кБ. Значение по умолчанию~--- 1024. В качестве начального значения для параметра можете взять 2--4\% доступной памяти. Для веб-приложений обычно устанавливают низкие значения \lstinline!work_mem!, так как запросов обычно много, но они простые, обычно хватает от 512 до 2048 КБ. С другой стороны, приложения для поддержки принятия решений с сотнями столбцов в каждом запросе и десятками миллионов строк в таблицах фактов часто требуют \lstinline!work_mem! порядка 500 МБ. Для баз данных, которые используются и так, и так, этот параметр можно устанавливать для каждого запроса индивидуально, используя настройки сессии.


\subsubsection{Максимальное количество клиентов: max\_connections}


Параметр \lstinline!max_connections! устанавливает максимальное количество клиентов, которые могут подключиться к PostgreSQL. Поскольку для каждого клиента требуется выделять память (\lstinline!work_mem!), то этот параметр предполагает максимально возможное использование памяти для всех клиентов. Как правило, PostgreSQL может поддерживать несколько сотен подключений, но создание нового является дорогостоящей операцией. Поэтому, если требуются тысячи подключений, то лучше использовать пул подключений (отдельная программа или библиотека в системе, что использует базу).


\subsubsection{Память для работы команды VACUUM: maintenance\_work\_mem}


Этот параметр задаёт объём памяти, используемый командами \lstinline!VACUUM!, \lstinline!ANALYZE!, \lstinline!CREATE INDEX!, и добавления внешних ключей. Чтобы операции выполнялись максимально быстро, нужно устанавливать этот параметр тем выше, чем больше размер таблиц в вашей базе данных. Неплохо бы устанавливать его значение от 50 до 75\% размера вашей самой большой таблицы или индекса. Следует устанавливать большее значение, чем для \lstinline!work_mem!. Слишком большие значения приведут к использованию свопа.


\subsubsection{Большие страницы: huge\_pages}


В PostgreSQL, начиная с версии 9.4, появилась поддержка больших страниц. В ОС Linux работа с памятью основывается на обращении к страницам размер которых равен 4kB (на самом деле зависит от платформы, проверить можно через \lstinline!getconf PAGE_SIZE!). Так вот, когда объем памяти переваливает за несколько десятков, а то и сотни гигабайт, управлять ею становится сложнее, увеличиваются накладные расходы на адресацию памяти и поддержание страничных таблиц. Для облегчения жизни и были придуманы большие страницы, размер которых может быть 2MB, а то и 1GB. За счет использования больших страниц можно получить ощутимый прирост скорости работы и увеличение отзывчивости в приложениях которые активно работают с памятью.

Для начала следует убедиться, что ядро поддерживает большие страницы. Проверяем конфиг ядра на предмет наличия опций \lstinline!CONFIG_HUGETLBFS! и \lstinline!CONFIG_HUGETLB_PAGE!.

\begin{lstlisting}[language=Bash,label=lst:settings_hugepages1,caption=Проверка конфига ядра на поддержку huge pages]
$ grep HUGETLB /boot/config-$(uname -r)
CONFIG_CGROUP_HUGETLB=y
CONFIG_HUGETLBFS=y
CONFIG_HUGETLB_PAGE=y
\end{lstlisting}

В случае отсутствия этих опций, ничего не заработает и ядро следует пересобрать.

Очевидно, что нам понадобится PostgreSQL версии не ниже 9.4. За поддержку больших страниц отвечает параметр \lstinline!huge_page!, который может принимать три значения: \lstinline!off!~--- не использовать большие страницы, \lstinline!on!~--- использовать большие страницы, \lstinline!try!~--- попытаться использовать большие страницы и в случае недоступности откатиться на использование обычных страниц. Значение \lstinline!try! используется по умолчанию и является безопасным вариантом. В случае \lstinline!on!, PostgreSQL не запустится, если большие страницы не определены в системе (или их недостаточно).

После перезапуска базы с параметром \lstinline!try! потребуется включить поддержку больших страниц в системе (по умолчанию они не задействованы). Расчет страниц приблизительный и здесь следует опираться на то, сколько памяти вы готовы выделить под нужды СУБД. Отмечу, что значение измеряется в страницах размером 2Mb, если вы хотите выделить 16GB, то это будет 8000 страниц.

Официальная документация предлагает опираться на значение \lstinline!VmPeak! из status файла, который размещен в \lstinline!/proc/PID/! директории, соответствующей номеру процесса postmaster. \lstinline!VmPeak! как следует из названия это пиковое значение использования виртуальной памяти. Этот вариант позволяет определить минимальную планку, от которой следует отталкиваться, но на мой взгляд такой способ определения тоже носит случайный характер.

\begin{lstlisting}[language=Bash,label=lst:settings_hugepages2,caption=Включаем поддержку huge pages в системе]
$ head -1 /var/lib/pgsql/9.5/data/postmaster.pid
3076
$ grep ^VmPeak /proc/3076/status
VmPeak:  4742563 kB
$ echo $((4742563 / 2048 + 1))
2316
$ echo 'vm.nr_hugepages = 2316' >> /etc/sysctl.d/30-postgresql.conf
$ sysctl -p --system
\end{lstlisting}

В ОС Linux есть также система по менеджменту памяти под названием <<Transparent HugePages>>, которая включена по умолчанию. Она может вызывать проблему при работе с huge pages для PostgreSQL, поэтому рекомендуется выключать этот механизм:

\begin{lstlisting}[language=Bash,label=lst:settings_hugepages3,caption=Отключаем Transparent HugePages]
$ echo never > /sys/kernel/mm/transparent_hugepage/defrag
$ echo never > /sys/kernel/mm/transparent_hugepage/enabled
\end{lstlisting}

После этого перезапускаем PostgreSQL и смотрим использование больших страниц:

\begin{lstlisting}[language=Bash,label=lst:settings_hugepages4,caption=Проверяем использование huge pages]
$ grep ^HugePages /proc/meminfo
HugePages_Total:    2316
HugePages_Free:     2301
HugePages_Rsvd:      128
HugePages_Surp:        0
\end{lstlisting}


\subsubsection{Прочие настройки}

\begin{itemize}
  \item \lstinline!temp_buffers!~--- буфер под временные объекты, в основном для временных таблиц. Можно установить порядка 16 МБ;
  \item \lstinline!max_prepared_transactions!~--- количество одновременно подготавливаемых транзакций (PREPARE TRANSACTION). Можно оставить по умолчанию~--- 0;
  \item \lstinline!vacuum_cost_delay!~--- если у вас большие таблицы, и производится много одновременных операций записи, вам может пригодиться функция, которая уменьшает затраты на I/O для VACUUM, растягивая его по времени. Чтобы включить эту функциональность, нужно поднять значение \lstinline!vacuum_cost_delay! выше 0. Используйте разумную задержку от 50 до 200 мс. Для более тонкой настройки повышайте \lstinline!vacuum_cost_page_hit! и понижайте \lstinline!vacuum_cost_limit!. Это ослабит влияние VACUUM, увеличив время его выполнения. В тестах с параллельными транзакциями Ян Вик (Jan Wieck) получил, что при значениях \lstinline!delay!~--- 200, \lstinline!page_hit!~--- 6 и \lstinline!limit!~---100 влияние VACUUM уменьшилось более чем на 80\%, но его длительность увеличилась втрое;
  \item \lstinline!max_stack_depth!~--- cпециальный стек для сервера, который в идеале должен совпадать с размером стека, выставленном в ядре ОС. Установка большего значения, чем в ядре, может привести к ошибкам. Рекомендуется устанавливать 2--4 MB;
  \item \lstinline!max_files_per_process!~--- максимальное количество файлов, открываемых процессом и его подпроцессами в один момент времени. Уменьшите данный параметр, если в процессе работы наблюдается сообщение <<Too many open files>>;
\end{itemize}


\subsection{Журнал транзакций и контрольные точки}


Для обеспечения отказоустойчивости СУБД PostgreSQL, как и многие базы данных, использует специальный журнал, в котором ведет историю изменения данных. Перед тем как записать данные в файлы БД, сервер PostgreSQL аккумулирует изменения в оперативной памяти и записывает в последовательный файл журнала, чтобы не потерять их из-за непредвиденного краха базы.

Данные в журнал пишутся до того как пользователь базы данных получит сообщение об успешном применении изменений. Этот журнал называется журналом упреждающей записи (Write-Ahead Log или просто WAL), а файлы журнала хранятся в каталоге \lstinline!pg_wal!. Также периодически PostgreSQL сбрасывает измененные аккумулированные данные из оперативной памяти на диск. Этот процесс согласования данных называется контрольной точкой (\lstinline!checkpoint!). Контрольная точка выполняется также при каждом штатном выключении PostgreSQL.

В этом случае нет необходимости сбрасывать на диск изменения данных при каждом успешном завершении транзакции: в случае сбоя БД может быть восстановлена по записям в журнале. Таким образом, данные из буферов сбрасываются на диск при проходе контрольной точки: либо при достижении определенного размера (параметры \lstinline!min_wal_size! и \lstinline!max_wal_size!) журнала транзакций, либо через определённый интервал времени (параметр \lstinline!checkpoint_timeout!, измеряется в секундах, по умолчанию 300 секунд).

Изменение этих параметров прямо не повлияет на скорость чтения, но может принести большую пользу, если данные в базе активно изменяются.


\subsubsection{Уменьшение количества контрольных точек: checkpoint\_segments}


Если в базу заносятся большие объёмы данных, то контрольные точки могут происходить слишком часто (<<слишком часто>> можно определить как <<чаще раза в минуту>>. Вы также можете задать параметр \lstinline!checkpoint_warning! (в секундах): в журнал сервера будут писаться предупреждения, если контрольные точки происходят чаще заданного). При этом производительность упадёт из-за постоянного сбрасывания на диск данных из буфера.

Для увеличения интервала между контрольными точками нужно увеличить количество сегментов журнала транзакций через параметр \lstinline!checkpoint_segments!. Данный параметр определяет количество сегментов (каждый по 16 МБ) лога транзакций между контрольными точками. Этот параметр не имеет особого значения для базы данных, предназначенной преимущественно для чтения, но для баз данных со множеством транзакций увеличение этого параметра может оказаться жизненно необходимым. В зависимости от объема данных установите этот параметр в диапазоне от 12 до 256 сегментов и, если в логе появляются предупреждения (warning) о том, что контрольные точки происходят слишком часто, постепенно увеличивайте его. Место, требуемое на диске, вычисляется по формуле \lstinline!(checkpoint_segments * (2 + checkpoint_completion_target) + 1) * 16! МБ, так что убедитесь, что у вас достаточно свободного места. Например, если вы выставите значение 32, вам потребуется больше 1 ГБ дискового пространства.

Следует также отметить, что чем больше интервал между контрольными точками, тем дольше будут восстанавливаться данные по журналу транзакций после сбоя.

Начиная с версии 9.5 \lstinline!checkpoint_segments! был заменен на параметры \lstinline!min_wal_size! и \lstinline!max_wal_size!. Теперь система может автоматически сама решать сколько \lstinline!checkpoint_segments! требуется хранить (вычислять по ранее приведенной формуле от указанного размера). Преимуществом этого является то, что вы можете установить \lstinline!max_wal_size! очень большим, но система не будет на самом деле потреблять указанное количество места на жестком диске, если в этом нет никакой необходимости. \lstinline!min_wal_size! устанавливает минимальный размер места, который будет использоваться сегментами (можно отключить такую автонастройку, установив для \lstinline!min_wal_size! и \lstinline!max_wal_size! одинаковое значение).


\subsubsection{fsync, synchronous\_commit и стоит ли их трогать}


Для увеличения производительности наиболее радикальное из возможных решений~--- выставить значение <<off>> параметру \lstinline!fsync!. При этом записи в журнале транзакций не будут принудительно сбрасываться на диск, что даст большой прирост скорости записи. Учтите: вы жертвуете надёжностью, в случае сбоя целостность базы будет нарушена, и её придётся восстанавливать из резервной копии! Использовать этот параметр рекомендуется лишь в том случае, если вы всецело доверяете своему <<железу>> и своему источнику бесперебойного питания. Ну или если данные в базе не представляют для вас особой ценности.

Параметр \lstinline!synchronous_commit! определяет нужно ли ждать WAL записи на диск перед возвратом успешного завершения транзакции для подключенного клиента. По умолчанию и для безопасности данный параметр установлен в <<on>> (включен). При выключении данного параметра (<<off>>) может существовать задержка между моментом, когда клиенту будет сообщено об успехе транзакции и когда та самая транзакция действительно гарантированно и безопасно записана на диск (максимальная задержка~--- \lstinline!wal_writer_delay * 3!). В отличие от \lstinline!fsync!, отключение этого параметра не создает риск краха базы данных: данные могут быть потеряны (последний набор транзакций), но базу данных не придется восстанавливать после сбоя из бэкапа. Так что \lstinline!synchronous_commit! может быть полезной альтернативой, когда производительность важнее, чем точная уверенность в согласовании данных (данный режим можно назвать <<режимом MongoDB>>: изначально все клиенты для MongoDB не проверяли успешность записи данных в базу и за счет этого достигалась хорошая скорость для бенчмарков).


\subsubsection{Прочие настройки}


\begin{itemize}
  \item \lstinline!commit_delay! (в микросекундах, 0 по умолчанию) и \lstinline!commit_siblings! (5 по умолчанию) определяют задержку между попаданием записи в буфер журнала транзакций и сбросом её на диск. Если при успешном завершении транзакции активно не менее \lstinline!commit_siblings! транзакций, то запись будет задержана на время \lstinline!commit_delay!. Если за это время завершится другая транзакция, то их изменения будут сброшены на диск вместе, при помощи одного системного вызова. Эти параметры позволят ускорить работу, если параллельно выполняется много <<мелких>> транзакций;

  \item \lstinline!wal_sync_method! Метод, который используется для принудительной записи данных на диск. Если \lstinline!fsync=off!, то этот параметр не используется. Возможные значения:
  \begin{itemize}
    \item \lstinline!open_datasync!~--- запись данных методом open() с параметром \lstinline!O_DSYNC!;
    \item \lstinline!fdatasync!~--- вызов метода fdatasync() после каждого commit;
    \item \lstinline!fsync_writethrough!~--- вызов fsync() после каждого commit, игнорируя параллельные процессы;
    \item \lstinline!fsync!~--- вызов fsync() после каждого commit;
    \item \lstinline!open_sync!~--- запись данных методом open() с параметром \lstinline!O_SYNC!;
  \end{itemize}

  Не все эти методы доступны на разных ОС. По умолчанию устанавливается первый, который доступен для системы;

  \item \lstinline!full_page_writes! Установите данный параметр в <<off>>, если \lstinline!fsync=off!. Иначе, когда этот параметр <<on>>, PostgreSQL записывает содержимое каждой записи в журнал транзакций при первой модификации таблицы. Это необходимо, поскольку данные могут записаться лишь частично, если в ходе процесса <<упала>> ОС. Это приведет к тому, что на диске окажутся новые данные смешанные со старыми. Строкового уровня записи в журнал транзакций может быть недостаточно, чтобы полностью восстановить данные после <<падения>>. \lstinline!full_page_writes! гарантирует корректное восстановление, ценой увеличения записываемых данных в журнал транзакций (Единственный способ снижения объема записи в журнал транзакций заключается в увеличении \lstinline!checkpoint_interval!);

  \item \lstinline!wal_buffers! Количество памяти, используемое в Shared Memory для ведения транзакционных логов (буфер находится в разделяемой памяти и является общим для всех процессов). Стоит увеличить буфер до 256--512 кБ, что позволит лучше работать с большими транзакциями. Например, при доступной памяти 1--4 ГБ рекомендуется устанавливать 256--1024 КБ;
\end{itemize}


\subsection{Планировщик запросов}


Следующие настройки помогают планировщику запросов правильно оценивать стоимости различных операций и выбирать оптимальный план выполнения запроса. Существуют 3 настройки планировщика, на которые стоит обратить внимание:

\begin{itemize}
  \item \lstinline!default_statistics_target!~--- этот параметр задаёт объём статистики, собираемой командой \lstinline!ANALYZE!. Увеличение параметра заставит эту команду работать дольше, но может позволить оптимизатору строить более быстрые планы, используя полученные дополнительные данные. Объём статистики для конкретного поля может быть задан командой \lstinline!ALTER TABLE ... SET STATISTICS!;

  \item \lstinline!effective_cache_size!~--- этот параметр сообщает PostgreSQL примерный объём файлового кэша операционной системы, оптимизатор использует эту оценку для построения плана запроса (указывает планировщику на размер самого большого объекта в базе данных, который теоретически может быть закеширован). Пусть в вашем компьютере 1.5 ГБ памяти, параметр \lstinline!shared_buffers! установлен в 32 МБ, а параметр \lstinline!effective_cache_size! в 800 МБ. Если запросу нужно 700 МБ данных, то PostgreSQL оценит, что все нужные данные уже есть в памяти и выберет более агрессивный план с использованием индексов и merge joins. Но если \lstinline!effective_cache_size! будет всего 200 МБ, то оптимизатор вполне может выбрать более эффективный для дисковой системы план, включающий полный просмотр таблицы.

На выделенном сервере имеет смысл выставлять \lstinline!effective_cache_size! в 2/3 от всей оперативной памяти; на сервере с другими приложениями сначала нужно вычесть из всего объема RAM размер дискового кэша ОС и память, занятую остальными процессами;

  \item \lstinline!random_page_cost!~--- переменная, указывающая на условную стоимость индексного доступа к страницам данных. На серверах с быстрыми дисковыми массивами имеет смысл уменьшать изначальную настройку до 3.0, 2.5 или даже до 2.0. Если же активная часть вашей базы данных намного больше размеров оперативной памяти, попробуйте поднять значение параметра. Можно подойти к выбору оптимального значения и со стороны производительности запросов. Если планировщик запросов чаще, чем необходимо, предпочитает последовательные просмотры (sequential scans) просмотрам с использованием индекса (index scans), понижайте значение. И наоборот, если планировщик выбирает просмотр по медленному индексу, когда не должен этого делать, настройку имеет смысл увеличить. После изменения тщательно тестируйте результаты на максимально широком наборе запросов. Никогда не опускайте значение \lstinline!random_page_cost! ниже 2.0; если вам кажется, что \lstinline!random_page_cost! нужно еще понижать, разумнее в этом случае менять настройки статистики планировщика.
\end{itemize}


\subsection{Сбор статистики}


У PostgreSQL также есть специальная подсистема~--- сборщик статистики,~--- которая в реальном времени собирает данные об активности сервера. Поскольку сбор статистики создает дополнительные накладные расходы на базу данных, то система может быть настроена как на сбор, так и не сбор статистики вообще. Эта система контролируется следующими параметрами, принимающими значения \lstinline!true/false!:

\begin{itemize}
  \item \lstinline!track_counts!~--- включать ли сбор статистики. По умолчанию включён, поскольку autovacuum демону требуется сбор статистики. Отключайте, только если статистика вас совершенно не интересует (как и autovacuum);
  \item \lstinline!track_functions!~--- отслеживание использования определенных пользователем функций;
  \item \lstinline!track_activities!~--- передавать ли сборщику статистики информацию о текущей выполняемой команде и времени начала её выполнения. По умолчанию эта возможность включена. Следует отметить, что эта информация будет доступна только привилегированным пользователям и пользователям, от лица которых запущены команды, так что проблем с безопасностью быть не должно;
\end{itemize}

Данные, полученные сборщиком статистики, доступны через специальные системные представления. При установках по умолчанию собирается очень мало информации, рекомендуется включить все возможности: дополнительная нагрузка будет невелика, в то время как полученные данные позволят оптимизировать использование индексов (а также помогут оптимальной работе autovacuum демону).
